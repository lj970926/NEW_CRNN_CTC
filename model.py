'''
the crnn_ctc mode implemented by tensorflow
author by lijin
'''

import tensorflow as tf
import numpy as np
import tensorflow.contrib.slim as slim
import tensorflow.contrib.rnn as rnn

BATCH_DECAY = 0.999


class CRNNModel(object):
    def __init__(self, hidden_num, layer_num, class_num, phase):
        '''
        get feature from the initial picture
        the h dimension of the pictuure must be 32
        :param hidden_num: the number of the hidden units
        :param layer_num: the number of the layers
        :param class_num:the number of types in dataset to be identified
        '''
        self.hidden_num = hidden_num
        self.layer_num = layer_num
        self.class_num = class_num
        self.phase = phase

    def get_feature_map(self, X):
        '''

        :param X: the input tensor
        :return: a feature map that has two dimension
        '''
        with slim.arg_scope([slim.conv2d], padding='SAME',
                            weights_initializer=tf.truncated_normal_initializer(stddev=0.01),
                            weights_regularizer=slim.l2_regularizer(0.0005),
                            activation_fn=tf.nn.relu):
            net = slim.repeat(X, 2, slim.conv2d, 64, kernel_size=3, stride=1, scope='conv1')
            net = slim.max_pool2d(net, kernel_size=2, stride=2, scope='pool1')
            net = slim.repeat(net, 2, slim.conv2d, 128, kernel_size=3, stride=1, scope='conv2')
            net = slim.max_pool2d(net, kernel_size=2, stride=2, scope='pool2')
            net = slim.repeat(net, 2, slim.conv2d, 256, kernel_size=3, stride=1, scope='conv3')
            net = slim.repeat(net, 2, slim.conv2d, 256, kernel_size=3, stride=1, scope='conv4')
            net = slim.max_pool2d(net, [2, 1], stride=[2, 1], scope='pool3')
            net = slim.repeat(net, 2, slim.conv2d, 512, kernel_size=3, stride=1, scope='conv5')
            net = slim.batch_norm(net, decay=BATCH_DECAY, is_training=True, scope='bn1')
            net = slim.conv2d(net, 512, kernel_size=3, stride=1, scope='conv6')
            net = slim.batch_norm(net, decay=BATCH_DECAY, is_training=True, scope='bn2')
            net = slim.max_pool2d(net, kernel_size=[2, 1], stride=[2, 1], scope='pool5')
            net = slim.conv2d(net, 512, padding="VALID", kernel_size=[2, 1], stride=1, scope='conv7')
        return net

    def map_to_sequence(self, featuremap):
        '''
        squeeze the feature map to two dimension
        :param featuremap: the featuremap generated by fuction get_feature_map
        :return: a 2 dimension sequence
        '''
        shape = featuremap.get_shape().as_list()
        assert shape[1] == 1, 'dimension error,can not squeeze the feature map'
        return tf.squeeze(featuremap, axis=1)

    def ctc_predict(self, sequence, sequence_length):
        with tf.variable_scope('bio_listm'):
            fw_cell_list = [rnn.BasicLSTMCell(i, forget_bias=1.0) for i in [self.hidden_num] * self.layer_num]
            bw_cell_list = [rnn.BasicLSTMCell(i, forget_bias=1.0) for i in [self.hidden_num] * self.layer_num]
            lstm_output, _, _ = rnn.stack_bidirectional_dynamic_rnn(fw_cell_list, bw_cell_list, sequence,
                                                                    sequence_length=sequence_length, dtype=tf.float32)
            batch_size, _, hidden_num = sequence.get_shape().as_list()
            reshaped_output = tf.reshape(lstm_output, [-1, hidden_num])

            W = tf.Variable(tf.truncated_normal([hidden_num, self.class_num], stddev=0.01), name='weight')
            logits = tf.matmul(reshaped_output, W)
            logits = tf.reshape(logits, [batch_size, -1, self.class_num])
            pre_result = tf.nn.softmax(logits)
            raw_predict = tf.argmax(pre_result, axis=2,name='raw_prediction')
            rnn_out = tf.transpose(logits, (1, 0, 2), name='transpose_time_major')
            return rnn_out,raw_predict

    def build_network(self, images, sequence_length=None):
        # first apply the cnn feature extraction stage
        cnn_out = self.get_feature_map(images)
        # second apply the map to sequence stage
        sequence = self.map_to_sequence(featuremap=cnn_out)
        # third apply the sequence label stage
        net_out, raw_pred = self.ctc_predict(sequence=sequence, sequence_length=sequence_length)
        return net_out
